if(runif(1) <= (proposal / current)) {
current <- proposal
}
else {
current <- current - direction
if(current < 1)
current <- 10
else if(current > 10)
current <- 1
}
df <- rbind(df, data.frame(step = i, island = current))
print(df)
}
ggplot(df, aes(x = step, y = current)) +
geom_line() +
labs(title = "Trace of Current over Steps",
x = "Step",
y = "Island")
library(ggplot2)
islands <- seq(1, 10, 1)
current <- sample(islands, 1)
current
left.right <- c(-1, 1)
df <- data.frame(step = integer(0), island = integer(0))
for(i in 1:1000) {
direction <- sample(left.right, 1)
proposal <- current + direction
if(proposal < 1)
proposal <- 10
else if(proposal > 10)
proposal <- 1
if(runif(1) <= (proposal / current)) {
current <- proposal
}
else {
current <- current - direction
if(current < 1)
current <- 10
else if(current > 10)
current <- 1
}
df <- rbind(df, data.frame(step = i, island = current))
}
ggplot(df, aes(x = step, y = island)) +
geom_line() +
labs(title = "Trace of Current over Steps",
x = "Step",
y = "Island")
ggplot(df, aes(x = step, y = island)) +
geom_line(linewidth = 0.5) +
labs(title = "Trace of Current over Steps",
x = "Step",
y = "Island")
ggplot(df, aes(x = step, y = island)) +
geom_line() +
labs(title = "Trace of Current over Steps",
x = "Step",
y = "Island")
ggplot(df, aes(x = step, y = factor(island))) +
geom_line() +
labs(title = "Trace of Current over Steps",
x = "Step",
y = "Island")
ggplot(df, aes(x = step, y = factor(current))) +
geom_line() +
labs(title = "Trace of Current over Steps",
x = "Step",
y = "Island")
ggplot(df, aes(x = step, y = factor(island))) +
geom_line() +
labs(title = "Trace of Current over Steps",
x = "Step",
y = "Island")
ggplot(df, aes(x = step, y = island)) +
geom_line() +
labs(title = "Trace of Current over Steps",
x = "Step",
y = "Island")
ggplot(df, aes(x = step, y = island)) +
geom_line() +
scale_y_continuous(breaks = 1:10) +
labs(title = "Trace of Current over Steps",
x = "Step",
y = "Island")
ggplot(df, aes(x = step, y = island)) +
geom_line() +
scale_y_continuous(breaks = islands) +
labs(title = "Trace of Current over Steps",
x = "Step",
y = "Island")
islands <- seq(1, 10, 1)
current <- sample(islands, 1)
current
left.right <- c(-1, 1)
df <- data.frame(step = integer(0), island = integer(0))
for(i in 1:1000) {
direction <- sample(left.right, 1)
proposal <- current + direction
if(proposal < 1)
proposal <- 10
else if(proposal > 10)
proposal <- 1
if(runif(1) <= (proposal / current)) {
current <- proposal
}
else {
current <- current - direction
if(current < 1)
current <- 10
else if(current > 10)
current <- 1
}
df <- rbind(df, data.frame(step = i, island = current))
}
ggplot(df, aes(x = step, y = island)) +
geom_line() +
scale_y_continuous(breaks = islands) +
labs(title = "Trace of Current over Steps",
x = "Step",
y = "Island")
ggplot(df, aes(x = step, y = island)) +
geom_line() +
scale_y_continuous(breaks = islands) +
labs(title = "Visited Islands",
x = "Step",
y = "Island")
library(rethinking)
ulam?
?ulam
?ulam
?quap
?ulam
# load packages
pacman::p_load(tidyverse, rethinking)
# load packages
pacman::p_load(tidyverse, rethinking)
# load dark theme
source("code/.R/dark_theme.R")
sim_pts <- function(FGA, FTA, hFG, hFT){
# FTA
FT <- rbinom(1, FTA, prob = hFT)
# 2PA
FG <- rbinom(1, FGA, prob = hFG) * 2
FT + FG + rnorm(1, mean=0, sd=4)
}
N_games <- 1e3
hFG <-  .7
hFT <-  .4
FGA <- round(rgamma(N_games, 20, 1),0)
FTA <- round(rgamma(N_games, 5, 1),0)
pts <- vector("numeric", length = N_games)
set.seed(123145)
#set.seed(1471)
for (i in seq_along(1:N_games)) {
pts[i] <-  sim_pts(FGA[i], FTA[i], hFG, hFT)
}
dat <- tibble(FGA, FTA, pts)
ggplot(dat, aes(x = pts)) +
geom_histogram(fill = "#ff02ff", alpha = .5, color = "#ff02ff", bins = 30) +
labs(x = "PTS",
y = "Frequency") #+
m1_shaq <- quap(
alist(
pts ~ dnorm(mu, sd),
mu <- a + b_1 * FGA * 2 + b_2 * FTA,
a ~ dunif(0,10),
b_1 ~ dunif(0, 1),
b_2 ~ dunif(0, 1),
sd ~ dunif(0,8)
),
data = dat)
pairs(m1_shaq, pars = c("a", "b_1", "b_2", "sd"))
FGA_bar <- round(mean(dat$FGA),0)
FTA_bar <- round(mean(dat$FTA),0)
m2_shaq <- quap(
alist(
pts ~ dnorm(mu, sd),
mu <- a + b_1 * (FGA-FGA_bar) * 2 + b_2 * (FTA-FTA_bar),
a ~ dnorm(20,8),
b_1 ~ dunif(0, 3),
b_2 ~ dunif(0, 1),
sd ~ dunif(0,8)
),
data = dat)
precis(m2_shaq)
plot(m2_shaq)
pairs(m2_shaq, pars = c("a", "b_1", "b_2", "sd"))
shaq <- read_csv("data/shaq.csv")
?ulam
# ulam ----
m4_shaq <- ulam(
alist(
PTS ~ dnorm(mu, sd),
mu <- a + b_1 * (MIN- MIN_bar) + b_2 * (FGA - FGA_bar) + b_3 * (FTA - FTA_bar),
a ~ dnorm(20, 8),
b_1 ~ dnorm(0, 2),
b_2 ~ dunif(0, 2),
b_3 ~ dunif(0, 1),
sd ~ dunif(0,8)
),
data = dat, chains = 4, cores = 2, iter = 4000)
install.packages(rstan)
library(rethinking)
# ulam ----
m4_shaq <- ulam(
alist(
PTS ~ dnorm(mu, sd),
mu <- a + b_1 * (MIN- MIN_bar) + b_2 * (FGA - FGA_bar) + b_3 * (FTA - FTA_bar),
a ~ dnorm(20, 8),
b_1 ~ dnorm(0, 2),
b_2 ~ dunif(0, 2),
b_3 ~ dunif(0, 1),
sd ~ dunif(0,8)
),
data = dat, chains = 4, cores = 2, iter = 4000)
install.packages("rstan")
library(rstan)
# ulam ----
m4_shaq <- ulam(
alist(
PTS ~ dnorm(mu, sd),
mu <- a + b_1 * (MIN- MIN_bar) + b_2 * (FGA - FGA_bar) + b_3 * (FTA - FTA_bar),
a ~ dnorm(20, 8),
b_1 ~ dnorm(0, 2),
b_2 ~ dunif(0, 2),
b_3 ~ dunif(0, 1),
sd ~ dunif(0,8)
),
data = dat, chains = 4, cores = 2, iter = 4000)
# load packages
pacman::p_load(tidyverse, rethinking)
# load dark theme
source("code/.R/dark_theme.R")
sim_pts <- function(FGA, FTA, hFG, hFT){
# FTA
FT <- rbinom(1, FTA, prob = hFT)
# 2PA
FG <- rbinom(1, FGA, prob = hFG) * 2
FT + FG + rnorm(1, mean=0, sd=4)
}
N_games <- 1e3
hFG <-  .7
hFT <-  .4
FGA <- round(rgamma(N_games, 20, 1),0)
FTA <- round(rgamma(N_games, 5, 1),0)
pts <- vector("numeric", length = N_games)
set.seed(123145)
#set.seed(1471)
for (i in seq_along(1:N_games)) {
pts[i] <-  sim_pts(FGA[i], FTA[i], hFG, hFT)
}
dat <- tibble(FGA, FTA, pts)
ggplot(dat, aes(x = pts)) +
geom_histogram(fill = "#ff02ff", alpha = .5, color = "#ff02ff", bins = 30) +
labs(x = "PTS",
y = "Frequency") #+
m1_shaq <- quap(
alist(
pts ~ dnorm(mu, sd),
mu <- a + b_1 * FGA * 2 + b_2 * FTA,
a ~ dunif(0,10),
b_1 ~ dunif(0, 1),
b_2 ~ dunif(0, 1),
sd ~ dunif(0,8)
),
data = dat)
precis(m1_shaq)
plot(m1_shaq)
pairs(m1_shaq, pars = c("a", "b_1", "b_2", "sd"))
FGA_bar <- round(mean(dat$FGA),0)
FTA_bar <- round(mean(dat$FTA),0)
m2_shaq <- quap(
alist(
pts ~ dnorm(mu, sd),
mu <- a + b_1 * (FGA-FGA_bar) * 2 + b_2 * (FTA-FTA_bar),
a ~ dnorm(20,8),
b_1 ~ dunif(0, 3),
b_2 ~ dunif(0, 1),
sd ~ dunif(0,8)
),
data = dat)
precis(m2_shaq)
plot(m2_shaq)
pairs(m2_shaq, pars = c("a", "b_1", "b_2", "sd"))
shaq <- read_csv("data/shaq.csv")
m3_shaq <- quap(
alist(
PTS ~ dnorm(mu, sd),
mu <- a + b_1 * (MIN - MIN_bar),
a ~ dnorm(20, 8),
b_1 ~ dunif(0, 2),
sd ~ dunif(0,8)
),
data = dat)
precis(m3_shaq)
# ulam ----
m4_shaq <- ulam(
alist(
PTS ~ dnorm(mu, sd),
mu <- a + b_1 * (MIN- MIN_bar) + b_2 * (FGA - FGA_bar) + b_3 * (FTA - FTA_bar),
a ~ dnorm(20, 8),
b_1 ~ dnorm(0, 2),
b_2 ~ dunif(0, 2),
b_3 ~ dunif(0, 1),
sd ~ dunif(0,8)
),
data = dat, chains = 4, cores = 2, iter = 4000)
# ulam ----
m5shaq <- ulam(
alist(
pts ~ dnorm(mu, sigma),
mu <- a + b_1 * (min - min_bar) + b_2 * (fga - fga_bar) * 2 + b_3 * (fta - fta_bar),
a ~ dnorm(20, 8),
b_1 ~ dnorm(0, 2),
b_2 ~ dunif(0, 2),
b_3 ~ dunif(0, 1),
sigma ~ dunif(0,10)
),
data = dat, chains = 4, cores = 4, iter = 4000)
# ulam ----
m5shaq <- ulam(
alist(
pts ~ dnorm(mu, sigma),
mu <- a + b_1 * (min - min_bar) + b_2 * (fga - fga_bar) * 2 + b_3 * (fta - fta_bar),
a ~ dnorm(20, 8),
b_1 ~ dnorm(0, 2),
b_2 ~ dunif(0, 2),
b_3 ~ dunif(0, 1),
sigma ~ dunif(0,10)
),
data = dat, chains = 4, cores = 4, iter = 4000)
# load packages
pacman::p_load(tidyverse, rethinking)
# load dark theme
source("code/.R/dark_theme.R")
sim_pts <- function(FGA, FTA, hFG, hFT){
# FTA
FT <- rbinom(1, FTA, prob = hFT)
# 2PA
FG <- rbinom(1, FGA, prob = hFG) * 2
FT + FG + rnorm(1, mean=0, sd=4)
}
N_games <- 1e3
hFG <-  .7
hFT <-  .4
FGA <- round(rgamma(N_games, 20, 1),0)
FTA <- round(rgamma(N_games, 5, 1),0)
pts <- vector("numeric", length = N_games)
set.seed(123145)
#set.seed(1471)
for (i in seq_along(1:N_games)) {
pts[i] <-  sim_pts(FGA[i], FTA[i], hFG, hFT)
}
dat <- tibble(FGA, FTA, pts)
ggplot(dat, aes(x = pts)) +
geom_histogram(fill = "#ff02ff", alpha = .5, color = "#ff02ff", bins = 30) +
labs(x = "PTS",
y = "Frequency") #+
m1_shaq <- quap(
alist(
pts ~ dnorm(mu, sd),
mu <- a + b_1 * FGA * 2 + b_2 * FTA,
a ~ dunif(0,10),
b_1 ~ dunif(0, 1),
b_2 ~ dunif(0, 1),
sd ~ dunif(0,8)
),
data = dat)
precis(m1_shaq)
plot(m1_shaq)
pairs(m1_shaq, pars = c("a", "b_1", "b_2", "sd"))
FGA_bar <- round(mean(dat$FGA),0)
FTA_bar <- round(mean(dat$FTA),0)
m2_shaq <- quap(
alist(
pts ~ dnorm(mu, sd),
mu <- a + b_1 * (FGA-FGA_bar) * 2 + b_2 * (FTA-FTA_bar),
a ~ dnorm(20,8),
b_1 ~ dunif(0, 3),
b_2 ~ dunif(0, 1),
sd ~ dunif(0,8)
),
data = dat)
precis(m2_shaq)
plot(m2_shaq)
pairs(m2_shaq, pars = c("a", "b_1", "b_2", "sd"))
shaq <- read_csv("data/shaq.csv")
dat <- list(FGA = shaq$FGA ,
FTA = shaq$FTA ,
PTS = shaq$PTS ,
MIN = shaq$Minutes ,
FTA_bar = round(mean(shaq$FTA),0) ,
FGA_bar = round(mean(shaq$FGA),0) ,
MIN_bar = round(mean(shaq$FGA),0))
ggplot(shaq, aes(x = Minutes, y = PTS)) +
geom_point(size = 2, color =  "#ff02ff", alpha = .5) +
labs(x = "Minutes",
y = "Points") # +
m3_shaq <- quap(
alist(
PTS ~ dnorm(mu, sd),
mu <- a + b_1 * (MIN - MIN_bar),
a ~ dnorm(20, 8),
b_1 ~ dunif(0, 2),
sd ~ dunif(0,8)
),
data = dat)
precis(m3_shaq)
# ulam ----
m5shaq <- ulam(
alist(
pts ~ dnorm(mu, sigma),
mu <- a + b_1 * (min - min_bar) + b_2 * (fga - fga_bar) * 2 + b_3 * (fta - fta_bar),
a ~ dnorm(20, 8),
b_1 ~ dnorm(0, 2),
b_2 ~ dunif(0, 2),
b_3 ~ dunif(0, 1),
sigma ~ dunif(0,10)
),
data = dat, chains = 4, cores = 4, iter = 4000)
# ulam ----
shaq <- read_csv("data/shaq.csv")
# ulam ----
shaq <- read_csv("shaq.csv")
?glmnet+
install.packages("glmnet")
install.packages("glmnet")
library(tidyverse)
library(ggplot2)
library(ISLR)
library(glmnet)
?glmnet
# Separate the response variable (Salary) and predictor variables (all others)
# y <- HittersClean$Salary
# X <- model.matrix(Salary ~ ., data=HittersClean)[, -1]  # Removing the intercept column
# Standard Linear Regression Model
linear.models <- lm(Salary ~ ., data=hitters.clean)
linear.coefficients <- coef(linear.models)
print("Standard Linear Model Coefficients:")
print(linear.coefficients)
# Ridge Regression Model with λ = 70
ridge.model <- glmnet(X, hitters.clean$Salary, alpha = 0, lambda = 70, standardize = TRUE)
ridge.coefficients <- coef(ridge.model)
print("Ridge Regression Model Coefficients with λ = 70:")
print(ridge.coefficients)
# Compare the size of the coefficients
comparison <- data.frame(
Variable = rownames(ridge.coefficients),
Linear = as.vector(linear.coefficients),
Ridge = as.vector(ridge.coefficients)
)
print("Comparison of Coefficients:")
print(comparison)
set.seed(1122)
train.indices <- sample(1:nrow(hitters.clean), size = 0.7 * nrow(hitters.clean))
X.train <- X[train.indices, ]
y.train <- hitters.clean$Salary[train.indices]
X.test <- X[-train.indices, ]
y.test <- hitters.clean$Salary[-train.indices]
# Fit ridge regression models for a range of lambda values using cross-validation
lambda.seq <- 10^seq(10, -2, length = 100)  # Sequence of lambda values
ridge.cv <- cv.glmnet(X.train, y.train, alpha = 0, lambda = lambda.seq, standardize = TRUE)
# Find the best lambda based on cross-validation
best.lambda <- ridge.cv$lambda.min
print(paste("Best lambda:", best.lambda))
# Fit the ridge regression model using the best lambda
ridge.best <- glmnet(X.train, y.train, alpha = 0, lambda = best.lambda, standardize = TRUE)
# Predict on the test set
predictions <- predict(ridge.best, s = best.lambda, newx = X.test)
# Calculate the mean squared prediction error on the test set
mse <- mean((y.test - predictions)^2)
print(paste("Mean Squared Prediction Error on the test set:", mse))
# Compare the size of the coefficients in the ridge model with the best lambda
ridge.coefficients_best <- coef(ridge.best)
print("Ridge Regression Model Coefficients with best lambda:")
print(ridge.coefficients.best)
set.seed(1122)
train.indices <- sample(1:nrow(hitters.clean), size = 0.7 * nrow(hitters.clean))
X.train <- X[train.indices, ]
y.train <- hitters.clean$Salary[train.indices]
X.test <- X[-train.indices, ]
y.test <- hitters.clean$Salary[-train.indices]
# Fit ridge regression models for a range of lambda values using cross-validation
lambda.seq <- 10^seq(10, -2, length = 100)  # Sequence of lambda values
ridge.cv <- cv.glmnet(X.train, y.train, alpha = 0, lambda = lambda.seq, standardize = TRUE)
# Find the best lambda based on cross-validation
best.lambda <- ridge.cv$lambda.min
print(paste("Best lambda:", best.lambda))
# Fit the ridge regression model using the best lambda
ridge.best <- glmnet(X.train, y.train, alpha = 0, lambda = best.lambda, standardize = TRUE)
# Predict on the test set
predictions <- predict(ridge.best, s = best.lambda, newx = X.test)
# Calculate the mean squared prediction error on the test set
mse <- mean((y.test - predictions)^2)
print(paste("Mean Squared Prediction Error on the test set:", mse))
# Compare the size of the coefficients in the ridge model with the best lambda
ridge.coefficients.best <- coef(ridge.best)
print("Ridge Regression Model Coefficients with best lambda:")
print(ridge.coefficients.best)
# Fit a standard linear regression model for comparison
linear.model <- lm(Salary ~ ., data = hitters.clean[train.indices, ])
linear.coefficients <- coef(linear.model)
print("Standard Linear Model Coefficients:")
print(linear.coefficients)
# Create a comparison of coefficients
comparison <- data.frame(
Variable = rownames(ridge.coefficients_best),
Linear = as.vector(linear.coefficients),
Ridge = as.vector(ridge.coefficients_best)
)
print("Comparison of Coefficients:")
print(comparison)
